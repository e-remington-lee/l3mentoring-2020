{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('venv')",
   "metadata": {
    "interpreter": {
     "hash": "c5161659e0c4ba7248a1564d775f97f6b0cb1faea6f43745a651b61be4b2f423"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, TFGPT2Model, GPT2Config\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "All model checkpoint layers were used when initializing TFGPT2Model.\n",
      "\n",
      "All the layers of TFGPT2Model were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2Model for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\", add_prefix_space=True)\n",
    "# model = TFGPT2Model.from_pretrained(\"gpt2\", return_dict=True)\n",
    "model = TFGPT2Model.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[220, 220, 18435, 995]"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")['input_ids']\n",
    "tokenizer(\"  Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=\narray([[15902,    11,   428,   318,   257,  1332,   290,   314,   716,\n          257, 10214]])>, 'attention_mask': <tf.Tensor: shape=(1, 11), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])>}\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hi, this is a test and I am a bot\", return_tensors=\"tf\")\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPast'>\ntf.Tensor(\n[[[ 0.049586   -0.2191338  -0.22060315 ... -0.23256269 -0.08462568\n   -0.18015   ]\n  [ 0.4487133   0.12794214  0.45916533 ... -0.02554812  0.02860656\n    0.19434442]\n  [ 0.5233359   0.21706821 -0.04357781 ... -0.03384571  0.24853888\n    0.45464808]\n  ...\n  [-0.29279605 -0.71266806 -0.6777717  ...  0.03725895 -0.31483287\n    0.36645684]\n  [ 0.06012781  0.2515111   0.5805898  ... -0.2687615  -0.509544\n    0.44237489]\n  [ 0.46943504  0.02301278 -0.70128864 ...  0.19859311  0.14772446\n    0.48830646]]], shape=(1, 11, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "outputs = model(inputs)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(last_hidden_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}