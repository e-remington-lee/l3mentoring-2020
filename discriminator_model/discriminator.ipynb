{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0c5161659e0c4ba7248a1564d775f97f6b0cb1faea6f43745a651b61be4b2f423",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Helps view the longer sentences in the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_csv = \"../contradictory-my-dear-watson/test.csv\"\n",
    "train_csv = \"../contradictory-my-dear-watson/train.csv\"\n",
    "test_csv_mod = \"../contradictory-my-dear-watson/test_mod.csv\"\n",
    "train_csv_mod = \"../contradictory-my-dear-watson/train_mod.csv\"\n",
    "\n",
    "# possiible predictions are [0, 1, 2] corresponding to entailment, neutral, and contradiction\n",
    "# datset name: contradictory my dear watson\n",
    "# datset url: https://www.kaggle.com/c/contradictory-my-dear-watson/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_csv_data(target_file, modded_file):\n",
    "    with open(target_file, encoding=\"utf-8\") as rf:\n",
    "        with open(modded_file, \"w\", newline=\"\\n\") as wf:\n",
    "            writer = csv.writer(wf)\n",
    "            csv_reader = csv.reader(rf, delimiter=\",\")\n",
    "            headers = next(csv_reader)\n",
    "            writer.writerow(headers)\n",
    "            count = 1\n",
    "            for row in csv_reader:\n",
    "                if row[3]==\"en\":\n",
    "                    try:\n",
    "                        writer.writerow(row)\n",
    "                        count+=1\n",
    "                    except UnicodeEncodeError:\n",
    "                        print(count)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2153\n3476\n4509\n"
     ]
    }
   ],
   "source": [
    "# only run if you need to remake english csv files\n",
    "# parse_raw_csv_data(train_csv, train_csv_mod)\n",
    "# parse_raw_csv_data(test_csv, test_csv_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted the last line of the csv file to make it work, the last line is blank and for some reason it doesn't like that\n",
    "train = pd.read_csv(train_csv_mod, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  \\\n",
       "0  5130fd2cb5   \n",
       "1  5b72532a0b   \n",
       "2  5622f0c60b   \n",
       "3  fdcd1bd867   \n",
       "4  7cfb3d272c   \n",
       "\n",
       "                                                                                        premise  \\\n",
       "0                          and these comments were considered in formulating the interim rules.   \n",
       "1             These are issues that we wrestle with in practice groups of law firms, she said.    \n",
       "2  you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
       "3                                                         From Cockpit Country to St. Ann's Bay   \n",
       "4                Look, it's your skin, but you're going to be in trouble if you don't get busy.   \n",
       "\n",
       "                                                                          hypothesis  \\\n",
       "0  The rules developed in the interim were put together with these comments in mind.   \n",
       "1                         Practice groups are not permitted to work on these issues.   \n",
       "2                                 They can't defend themselves because of their age.   \n",
       "3                                             From St. Ann's Bay to Cockpit Country.   \n",
       "4                                The boss will fire you if he sees you slacking off.   \n",
       "\n",
       "  lang_abv language  label  \n",
       "0       en  English      0  \n",
       "1       en  English      2  \n",
       "2       en  English      0  \n",
       "3       en  English      2  \n",
       "4       en  English      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lang_abv</th>\n      <th>language</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5130fd2cb5</td>\n      <td>and these comments were considered in formulating the interim rules.</td>\n      <td>The rules developed in the interim were put together with these comments in mind.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5b72532a0b</td>\n      <td>These are issues that we wrestle with in practice groups of law firms, she said.</td>\n      <td>Practice groups are not permitted to work on these issues.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5622f0c60b</td>\n      <td>you know they can't really defend themselves like somebody grown uh say my age you know yeah</td>\n      <td>They can't defend themselves because of their age.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fdcd1bd867</td>\n      <td>From Cockpit Country to St. Ann's Bay</td>\n      <td>From St. Ann's Bay to Cockpit Country.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7cfb3d272c</td>\n      <td>Look, it's your skin, but you're going to be in trouble if you don't get busy.</td>\n      <td>The boss will fire you if he sees you slacking off.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "   tokens = list(tokenizer.tokenize(s))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2122, 2024, 3314, 2008, 2057, 25579, 2007, 1999, 3218, 2967, 1997, 2375, 9786, 1010, 2016, 2056, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "print(encode_sentence(train.premise[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(hypotheses, premises, tokenizer):\n",
    "    \n",
    "  num_examples = len(hypotheses)\n",
    "  \n",
    "  sentence1 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "      for s in np.array(hypotheses)])\n",
    "  sentence2 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "       for s in np.array(premises)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_s1 = tf.zeros_like(sentence1)\n",
    "  type_s2 = tf.ones_like(sentence2)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "\n",
    "#   inputs = {\n",
    "#       'input_word_ids': input_word_ids.to_tensor(),\n",
    "#       'input_mask': input_mask,\n",
    "#       'input_type_ids': input_type_ids}\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor()\n",
    "      }\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 150\n",
    "# add recall\n",
    "\n",
    "def build_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32)\n",
    "    # input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    # input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "    \n",
    "    embedding = bert_encoder([input_word_ids])[0]\n",
    "    # to visualize what is going on\n",
    "    # print(embedding1)\n",
    "    # print(embedding1[0])\n",
    "    # print(embedding1[1])\n",
    "    # embedding = embedding1[0]\n",
    "\n",
    "    #numpy documentation describes the [:,0,:] notation, we basically drop the middle numpy array output\n",
    "    # print(embedding)\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
    "    \n",
    "    # model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
    "    model = tf.keras.Model(inputs=[input_word_ids], outputs=output)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000001F0D50C32E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x000001F0D50C32E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 150)]             0         \n_________________________________________________________________\ntf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 109482240 \n_________________________________________________________________\ntf_op_layer_strided_slice (T [(None, 768)]             0         \n_________________________________________________________________\ndense (Dense)                (None, 3)                 2307      \n=================================================================\nTotal params: 109,484,547\nTrainable params: 109,484,547\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e:\\Software\\L3Mentorship\\discriminator_model\n['checkpoints', 'discriminator.ipynb']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "checkpoint_path = \"checkpoints\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "print(os.listdir())\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_accuracy\",\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(\"input_1:0\", shape=(None, 150), dtype=int32), but it was called on an input with incompatible shape (None, 305).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(\"input_1:0\", shape=(None, 150), dtype=int32), but it was called on an input with incompatible shape (None, 305).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "684/684 [==============================] - ETA: 0s - loss: 1.1341 - accuracy: 0.3321WARNING:tensorflow:Model was constructed with shape (None, 150) for input Tensor(\"input_1:0\", shape=(None, 150), dtype=int32), but it was called on an input with incompatible shape (None, 305).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.32183, saving model to checkpoints\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:Assets written to: checkpoints\\assets\n",
      "684/684 [==============================] - 291s 425ms/step - loss: 1.1341 - accuracy: 0.3321 - val_loss: 1.1295 - val_accuracy: 0.3218\n",
      "Epoch 2/5\n",
      "399/684 [================>.............] - ETA: 1:39 - loss: 1.1243 - accuracy: 0.3236"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4975b0ffa27c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mvalidation_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         callbacks=[cp_callback])\n\u001b[0m",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[0;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1924\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_input, train.label.values, epochs =5,  verbose = 1,\n",
    "        batch_size = 10, \n",
    "        validation_split = 0.2,\n",
    "        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "## this solved an 'index out of range' error, must be something new\n",
    "# model2 = tf.keras.Model(model)\n",
    "\n",
    "model_folder = \"../model_path\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_name_save = \"discriminator_5870\"\n",
    "model_path = os.path.join(model_folder, model_name_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:Assets written to: ../model_path\\discriminator_5870\\assets\n"
     ]
    }
   ],
   "source": [
    "# new_model = keras.models.load_model(model_path)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = pd.read_csv(test_csv_mod)\n",
    "test_input = bert_encode(test_pd.premise.values, test_pd.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li = [np.argmax(i) for i in new_model.predict(test_input)]\n",
    "# li = [np.argmax(i) for i in model2.predict(test_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 2, 2, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 2, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 0, 1, 1, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 0, 2, 2, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 1, 2, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 1, 1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 2, 1, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 1, 2, 2, 2, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 2, 2, 0, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1, 2, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 2, 0, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 0, 2, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 2, 2, 1, 0, 1, 2, 0, 0, 2, 2, 0, 0, 2, 1, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 2, 2, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 0, 1, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 1, 1, 2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 2, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 0, 1, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  predictions\n",
       "0  aa2510d454            0\n",
       "1  865d1c7b16            1\n",
       "2  6d9fa191e6            0\n",
       "3  f11f1ffffe            2\n",
       "4  40a9b0f08e            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa2510d454</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>865d1c7b16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6d9fa191e6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f11f1ffffe</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40a9b0f08e</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sub = test_pd.id.copy().to_frame()\n",
    "sub[\"predictions\"] = li\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}