{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "c5161659e0c4ba7248a1564d775f97f6b0cb1faea6f43745a651b61be4b2f423"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Helps view the longer sentences in the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_csv = \"../contradictory-my-dear-watson/test.csv\"\n",
    "train_csv = \"../contradictory-my-dear-watson/train.csv\"\n",
    "test_csv_mod = \"../contradictory-my-dear-watson/test_mod.csv\"\n",
    "train_csv_mod = \"../contradictory-my-dear-watson/train_mod.csv\"\n",
    "\n",
    "# possiible predictions are [0, 1, 2] corresponding to entailment, neutral, and contradiction\n",
    "# datset name: contradictory my dear watson\n",
    "# datset url: https://www.kaggle.com/c/contradictory-my-dear-watson/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_csv_data(target_file, modded_file):\n",
    "    with open(target_file, encoding=\"utf-8\") as rf:\n",
    "        with open(modded_file, \"w\", newline=\"\\n\") as wf:\n",
    "            writer = csv.writer(wf)\n",
    "            csv_reader = csv.reader(rf, delimiter=\",\")\n",
    "            headers = next(csv_reader)\n",
    "            writer.writerow(headers)\n",
    "            count = 1\n",
    "            for row in csv_reader:\n",
    "                if row[3]==\"en\":\n",
    "                    try:\n",
    "                        writer.writerow(row)\n",
    "                        count+=1\n",
    "                    except UnicodeEncodeError:\n",
    "                        print(count)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only run if you need to remake english csv files\n",
    "# parse_raw_csv_data(train_csv, train_csv_mod)\n",
    "# parse_raw_csv_data(test_csv, test_csv_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted the last line of the csv file to make it work, the last line is blank and for some reason it doesn't like that\n",
    "train = pd.read_csv(train_csv_mod, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  \\\n",
       "0  5130fd2cb5   \n",
       "1  5b72532a0b   \n",
       "2  5622f0c60b   \n",
       "3  fdcd1bd867   \n",
       "4  7cfb3d272c   \n",
       "\n",
       "                                                                                        premise  \\\n",
       "0                          and these comments were considered in formulating the interim rules.   \n",
       "1             These are issues that we wrestle with in practice groups of law firms, she said.    \n",
       "2  you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
       "3                                                         From Cockpit Country to St. Ann's Bay   \n",
       "4                Look, it's your skin, but you're going to be in trouble if you don't get busy.   \n",
       "\n",
       "                                                                          hypothesis  \\\n",
       "0  The rules developed in the interim were put together with these comments in mind.   \n",
       "1                         Practice groups are not permitted to work on these issues.   \n",
       "2                                 They can't defend themselves because of their age.   \n",
       "3                                             From St. Ann's Bay to Cockpit Country.   \n",
       "4                                The boss will fire you if he sees you slacking off.   \n",
       "\n",
       "  lang_abv language  label  \n",
       "0       en  English      0  \n",
       "1       en  English      2  \n",
       "2       en  English      0  \n",
       "3       en  English      2  \n",
       "4       en  English      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lang_abv</th>\n      <th>language</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5130fd2cb5</td>\n      <td>and these comments were considered in formulating the interim rules.</td>\n      <td>The rules developed in the interim were put together with these comments in mind.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5b72532a0b</td>\n      <td>These are issues that we wrestle with in practice groups of law firms, she said.</td>\n      <td>Practice groups are not permitted to work on these issues.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5622f0c60b</td>\n      <td>you know they can't really defend themselves like somebody grown uh say my age you know yeah</td>\n      <td>They can't defend themselves because of their age.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fdcd1bd867</td>\n      <td>From Cockpit Country to St. Ann's Bay</td>\n      <td>From St. Ann's Bay to Cockpit Country.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7cfb3d272c</td>\n      <td>Look, it's your skin, but you're going to be in trouble if you don't get busy.</td>\n      <td>The boss will fire you if he sees you slacking off.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "   tokens = list(tokenizer.tokenize(s))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2122, 2024, 3314, 2008, 2057, 25579, 2007, 1999, 3218, 2967, 1997, 2375, 9786, 1010, 2016, 2056, 1012, 102]\n"
     ]
    }
   ],
   "source": [
    "print(encode_sentence(train.premise[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(hypotheses, premises, tokenizer):\n",
    "    \n",
    "  num_examples = len(hypotheses)\n",
    "  \n",
    "  sentence1 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "      for s in np.array(hypotheses)])\n",
    "  sentence2 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "       for s in np.array(premises)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_s1 = tf.zeros_like(sentence1)\n",
    "  type_s2 = tf.ones_like(sentence2)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor(),\n",
    "      'input_mask': input_mask,\n",
    "      'input_type_ids': input_type_ids}\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 237\n",
    "# add recall\n",
    "\n",
    "def build_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "    \n",
    "    embedding1 = bert_encoder([input_word_ids, input_mask, input_type_ids])\n",
    "    # to visualize what is going on\n",
    "    print(embedding1)\n",
    "    print(embedding1[0])\n",
    "    print(embedding1[1])\n",
    "    embedding = embedding1[0]\n",
    "    # embedding = bert_encoder([input_word_ids, input_mask, input_type_ids])[0]\n",
    "\n",
    "    #numpy documentation describes the [:,0,:] notation, we basically drop the middle numpy array output\n",
    "    print(embedding)\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000023058BF32E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x0000023058BF32E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "TFBaseModelOutputWithPooling(last_hidden_state=<tf.Tensor 'tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0' shape=(None, 237, 768) dtype=float32>, pooler_output=<tf.Tensor 'tf_bert_model/bert/pooler/dense/Tanh:0' shape=(None, 768) dtype=float32>, hidden_states=None, attentions=None)\n",
      "Tensor(\"tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0\", shape=(None, 237, 768), dtype=float32)\n",
      "Tensor(\"tf_bert_model/bert/pooler/dense/Tanh:0\", shape=(None, 768), dtype=float32)\n",
      "Tensor(\"tf_bert_model/bert/encoder/layer_._11/output/LayerNorm/batchnorm/add_1:0\", shape=(None, 237, 768), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_word_ids (InputLayer)     [(None, 237)]        0                                            \n__________________________________________________________________________________________________\ninput_mask (InputLayer)         [(None, 237)]        0                                            \n__________________________________________________________________________________________________\ninput_type_ids (InputLayer)     [(None, 237)]        0                                            \n__________________________________________________________________________________________________\ntf_bert_model (TFBertModel)     TFBaseModelOutputWit 109482240   input_word_ids[0][0]             \n                                                                 input_mask[0][0]                 \n                                                                 input_type_ids[0][0]             \n__________________________________________________________________________________________________\ntf_op_layer_strided_slice (Tens [(None, 768)]        0           tf_bert_model[0][0]              \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 3)            2307        tf_op_layer_strided_slice[0][0]  \n==================================================================================================\nTotal params: 109,484,547\nTrainable params: 109,484,547\nNon-trainable params: 0\n__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e:\\Software\\L3Mentorship\\discriminator_model\n['checkpoints', 'discriminator.ipynb', 'model_path']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "checkpoint_path = \"checkpoints\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "print(os.listdir())\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_accuracy\",\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "5493/5493 [==============================] - ETA: 0s - loss: 0.8749 - accuracy: 0.5915The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "5493/5493 [==============================] - 313s 57ms/step - loss: 0.8749 - accuracy: 0.5915 - val_loss: 0.8250 - val_accuracy: 0.6543\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23039cafc08>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "model.fit(train_input, train.label.values, epochs = 1, verbose = 1,\n",
    "        batch_size = 1, \n",
    "        validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "## this solved an 'index out of range' error, must be something new\n",
    "model2 = tf.keras.Model(model)\n",
    "\n",
    "model_folder = \"../model_path\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_name = \"discriminator\"\n",
    "model_path = os.path.join(model_folder, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NotImplementedError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-557c9cec7497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[1;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[0;32m   1276\u001b[0m         \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m     \u001b[0mlayer_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'inbound_nodes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[1;34m(instance)\u001b[0m\n\u001b[0;32m    248\u001b[0m         return serialize_keras_class_and_config(\n\u001b[0;32m    249\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[1;32m--> 250\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    251\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[1;34m(instance)\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 245\u001b[1;33m       \u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2230\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2231\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2233\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.get_config()\n",
    "# NotImplementedError: When subclassing the `Model` class, you should implement a `call` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.engine.training.Model object at 0x00000230A3D861C8>, because it is not built.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ../model_path\\discriminator\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model2, model_path)\n",
    "# model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = pd.read_csv(test_csv_mod)\n",
    "test_input = bert_encode(test_pd.premise.values, test_pd.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# li = [np.argmax(i) for i in model2.predict(test_input)]\n",
    "model5 = tf.keras.models.load_model(model_path)\n",
    "li = [np.argmax(i) for i in model2.predict(test_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test_pd.id.copy().to_frame()\n",
    "sub[\"predictions\"] = li\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}