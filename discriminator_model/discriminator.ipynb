{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0c5161659e0c4ba7248a1564d775f97f6b0cb1faea6f43745a651b61be4b2f423",
   "display_name": "Python 3.7.7 64-bit ('venv': venv)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Helps view the longer sentences in the dataframe\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "test_csv = \"../contradictory-my-dear-watson/test.csv\"\n",
    "train_csv = \"../contradictory-my-dear-watson/train.csv\"\n",
    "test_csv_mod = \"../contradictory-my-dear-watson/test_mod.csv\"\n",
    "train_csv_mod = \"../contradictory-my-dear-watson/train_mod.csv\"\n",
    "\n",
    "# possiible predictions are [0, 1, 2] corresponding to entailment, neutral, and contradiction\n",
    "# datset name: contradictory my dear watson\n",
    "# datset url: https://www.kaggle.com/c/contradictory-my-dear-watson/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_csv_data(target_file, modded_file):\n",
    "    with open(target_file, encoding=\"utf-8\") as rf:\n",
    "        with open(modded_file, \"w\", newline=\"\\n\") as wf:\n",
    "            writer = csv.writer(wf)\n",
    "            csv_reader = csv.reader(rf, delimiter=\",\")\n",
    "            headers = next(csv_reader)\n",
    "            writer.writerow(headers)\n",
    "            count = 1\n",
    "            for row in csv_reader:\n",
    "                if row[3]==\"en\":\n",
    "                    try:\n",
    "                        writer.writerow(row)\n",
    "                        count+=1\n",
    "                    except UnicodeEncodeError:\n",
    "                        print(count)\n",
    "                        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only run if you need to remake english csv files\n",
    "# parse_raw_csv_data(train_csv, train_csv_mod)\n",
    "# parse_raw_csv_data(test_csv, test_csv_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted the last line of the csv file to make it work, the last line is blank and for some reason it doesn't like that\n",
    "train = pd.read_csv(train_csv_mod, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  \\\n",
       "0  5130fd2cb5   \n",
       "1  5b72532a0b   \n",
       "2  5622f0c60b   \n",
       "3  fdcd1bd867   \n",
       "4  7cfb3d272c   \n",
       "\n",
       "                                                                                        premise  \\\n",
       "0                          and these comments were considered in formulating the interim rules.   \n",
       "1             These are issues that we wrestle with in practice groups of law firms, she said.    \n",
       "2  you know they can't really defend themselves like somebody grown uh say my age you know yeah   \n",
       "3                                                         From Cockpit Country to St. Ann's Bay   \n",
       "4                Look, it's your skin, but you're going to be in trouble if you don't get busy.   \n",
       "\n",
       "                                                                          hypothesis  \\\n",
       "0  The rules developed in the interim were put together with these comments in mind.   \n",
       "1                         Practice groups are not permitted to work on these issues.   \n",
       "2                                 They can't defend themselves because of their age.   \n",
       "3                                             From St. Ann's Bay to Cockpit Country.   \n",
       "4                                The boss will fire you if he sees you slacking off.   \n",
       "\n",
       "  lang_abv language  label  \n",
       "0       en  English      0  \n",
       "1       en  English      2  \n",
       "2       en  English      0  \n",
       "3       en  English      2  \n",
       "4       en  English      1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n      <th>lang_abv</th>\n      <th>language</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5130fd2cb5</td>\n      <td>and these comments were considered in formulating the interim rules.</td>\n      <td>The rules developed in the interim were put together with these comments in mind.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5b72532a0b</td>\n      <td>These are issues that we wrestle with in practice groups of law firms, she said.</td>\n      <td>Practice groups are not permitted to work on these issues.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5622f0c60b</td>\n      <td>you know they can't really defend themselves like somebody grown uh say my age you know yeah</td>\n      <td>They can't defend themselves because of their age.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>fdcd1bd867</td>\n      <td>From Cockpit Country to St. Ann's Bay</td>\n      <td>From St. Ann's Bay to Cockpit Country.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7cfb3d272c</td>\n      <td>Look, it's your skin, but you're going to be in trouble if you don't get busy.</td>\n      <td>The boss will fire you if he sees you slacking off.</td>\n      <td>en</td>\n      <td>English</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(s):\n",
    "   tokens = list(tokenizer.tokenize(s))\n",
    "   tokens.append('[SEP]')\n",
    "   return tokenizer.convert_tokens_to_ids(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1636, 1132, 2492, 1115, 1195, 192, 22713, 1114, 1107, 2415, 2114, 1104, 1644, 9780, 117, 1131, 1163, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "print(encode_sentence(train.premise[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_encode(hypotheses, premises, tokenizer):\n",
    "    \n",
    "  num_examples = len(hypotheses)\n",
    "  \n",
    "  sentence1 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "      for s in np.array(hypotheses)])\n",
    "  sentence2 = tf.ragged.constant([\n",
    "      encode_sentence(s)\n",
    "       for s in np.array(premises)])\n",
    "\n",
    "  cls = [tokenizer.convert_tokens_to_ids(['[CLS]'])]*sentence1.shape[0]\n",
    "  input_word_ids = tf.concat([cls, sentence1, sentence2], axis=-1)\n",
    "\n",
    "  input_mask = tf.ones_like(input_word_ids).to_tensor()\n",
    "\n",
    "  type_cls = tf.zeros_like(cls)\n",
    "  type_s1 = tf.zeros_like(sentence1)\n",
    "  type_s2 = tf.ones_like(sentence2)\n",
    "  input_type_ids = tf.concat(\n",
    "      [type_cls, type_s1, type_s2], axis=-1).to_tensor()\n",
    "\n",
    "#   inputs = {\n",
    "#       'input_word_ids': input_word_ids.to_tensor(),\n",
    "#       'input_mask': input_mask,\n",
    "#       'input_type_ids': input_type_ids}\n",
    "  inputs = {\n",
    "      'input_word_ids': input_word_ids.to_tensor()\n",
    "      }\n",
    "\n",
    "  return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = bert_encode(train.premise.values, train.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200\n",
    "# add recall\n",
    "\n",
    "def build_model():\n",
    "    bert_encoder = TFBertModel.from_pretrained(model_name)\n",
    "    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    # input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n",
    "    # input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n",
    "    \n",
    "    embedding = bert_encoder([input_word_ids])[0]\n",
    "    # to visualize what is going on\n",
    "    # print(embedding1)\n",
    "    # print(embedding1[0])\n",
    "    # print(embedding1[1])\n",
    "    # embedding = embedding1[0]\n",
    "\n",
    "    #numpy documentation describes the [:,0,:] notation, we basically drop the middle numpy array output\n",
    "    # print(embedding)\n",
    "    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n",
    "    \n",
    "    # model = tf.keras.Model(inputs=[input_word_ids, input_mask, input_type_ids], outputs=output)\n",
    "    model = tf.keras.Model(inputs=[input_word_ids], outputs=output)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000247032332E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x00000247032332E8>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.Sequential([\n",
    "    # keras.layers\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"functional_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_word_ids (InputLayer)  [(None, 200)]             0         \n_________________________________________________________________\ntf_bert_model (TFBertModel)  TFBaseModelOutputWithPool 108310272 \n_________________________________________________________________\ntf_op_layer_strided_slice (T [(None, 768)]             0         \n_________________________________________________________________\ndense (Dense)                (None, 3)                 2307      \n=================================================================\nTotal params: 108,312,579\nTrainable params: 108,312,579\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e:\\Software\\L3Mentorship\\discriminator_model\n['checkpoints', 'discriminator.ipynb', 'model_path']\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "checkpoint_path = \"checkpoints\"\n",
    "os.makedirs(checkpoint_path, exist_ok=True)\n",
    "print(os.listdir())\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_best_only=True,\n",
    "                                                 monitor=\"val_accuracy\",\n",
    "                                                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_word_ids:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (1, 239).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_word_ids:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (1, 239).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "5493/5493 [==============================] - ETA: 0s - loss: 1.0136 - accuracy: 0.4792WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_word_ids:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (1, 239).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "5493/5493 [==============================] - 309s 56ms/step - loss: 1.0136 - accuracy: 0.4792 - val_loss: 0.8861 - val_accuracy: 0.6150\n",
      "Epoch 2/3\n",
      "5493/5493 [==============================] - 292s 53ms/step - loss: 0.6856 - accuracy: 0.7093 - val_loss: 0.8566 - val_accuracy: 0.6383\n",
      "Epoch 3/3\n",
      "5493/5493 [==============================] - 295s 54ms/step - loss: 0.3672 - accuracy: 0.8564 - val_loss: 1.0552 - val_accuracy: 0.6376\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2475daa9908>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "model.fit(train_input, train.label.values, epochs =3,  verbose = 1,\n",
    "        batch_size = 1, \n",
    "        validation_split = 0.2,\n",
    "        callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save model\n",
    "## this solved an 'index out of range' error, must be something new\n",
    "# model2 = tf.keras.Model(model)\n",
    "\n",
    "model_folder = \"../model_path\"\n",
    "os.makedirs(model_folder, exist_ok=True)\n",
    "model_name = \"discriminator\"\n",
    "model_path = os.path.join(model_folder, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From e:\\Software\\L3Mentorship\\venv\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "INFO:tensorflow:Assets written to: ../model_path\\discriminator\\assets\n"
     ]
    }
   ],
   "source": [
    "# tf.keras.models.save_model(model, model_path, overwrite=True)\n",
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd = pd.read_csv(test_csv_mod)\n",
    "test_input = bert_encode(test_pd.premise.values, test_pd.hypothesis.values, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 200) for input Tensor(\"input_word_ids:0\", shape=(None, 200), dtype=int32), but it was called on an input with incompatible shape (None, 230).\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    }
   ],
   "source": [
    "li = [np.argmax(i) for i in model.predict(test_input)]\n",
    "# model5 = tf.keras.models.load_model(model_path)\n",
    "# model5.call()\n",
    "# li = [np.argmax(i) for i in model2.predict(test_input)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0, 1, 0, 2, 0, 2, 2, 0, 0, 2, 2, 2, 1, 0, 2, 0, 0, 1, 0, 1, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 0, 0, 1, 2, 0, 2, 0, 1, 1, 2, 0, 0, 2, 2, 1, 2, 2, 2, 0, 1, 2, 1, 0, 2, 0, 0, 1, 2, 1, 1, 2, 1, 0, 0, 2, 0, 2, 2, 1, 1, 0, 1, 0, 2, 0, 2, 1, 2, 0, 1, 1, 1, 2, 2, 0, 1, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1, 1, 2, 0, 1, 1, 0, 2, 2, 2, 1, 0, 1, 0, 0, 0, 2, 2, 0, 2, 1, 2, 2, 1, 0, 0, 0, 1, 0, 0, 2, 2, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 0, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 0, 1, 2, 0, 1, 0, 1, 2, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 2, 1, 1, 1, 2, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 1, 2, 2, 0, 1, 1, 1, 2, 0, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 1, 2, 1, 2, 2, 2, 1, 0, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 0, 1, 1, 2, 1, 2, 2, 1, 1, 1, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 0, 2, 2, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 1, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 0, 0, 1, 1, 2, 2, 0, 1, 2, 1, 1, 0, 2, 2, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 1, 2, 0, 2, 0, 2, 1, 0, 1, 2, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 1, 1, 0, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 0, 1, 0, 1, 2, 1, 1, 2, 0, 0, 2, 0, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 1, 2, 0, 2, 0, 2, 2, 2, 2, 0, 2, 0, 2, 2, 0, 0, 1, 0, 1, 2, 2, 2, 1, 0, 2, 0, 0, 2, 2, 0, 1, 2, 1, 2, 0, 1, 0, 2, 2, 2, 0, 1, 1, 2, 0, 1, 0, 0, 2, 2, 1, 0, 0, 2, 2, 0, 2, 1, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0, 2, 0, 0, 2, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 1, 2, 0, 1, 1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 2, 1, 2, 0, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 1, 2, 2, 1, 0, 2, 1, 0, 0, 1, 0, 1, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 2, 2, 1, 0, 0, 1, 0, 0, 0, 1, 0, 2, 0, 2, 0, 2, 1, 1, 0, 0, 2, 1, 0, 1, 2, 0, 2, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 2, 1, 1, 0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 0, 2, 0, 1, 1, 0, 1, 0, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 0, 1, 2, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 1, 2, 1, 1, 2, 1, 0, 1, 0, 2, 2, 1, 2, 0, 0, 0, 1, 2, 2, 2, 2, 1, 2, 0, 0, 1, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 1, 1, 0, 2, 0, 1, 1, 0, 2, 1, 1, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 1, 0, 0, 2, 2, 0, 1, 0, 2, 2, 1, 0, 1, 0, 0, 0, 0, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 0, 1, 2, 1, 1, 0, 1, 2, 2, 2, 2, 0, 1, 0, 1, 1, 0, 2, 2, 0, 1, 2, 2, 2, 1, 0, 1, 0, 0, 1, 2, 1, 2, 2, 0, 1, 1, 0, 1, 2, 1, 0, 2, 0, 2, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 2, 2, 1, 1, 0, 1, 2, 0, 0, 1, 0, 2, 1, 2, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 2, 2, 0, 1, 0, 2, 1, 0, 1, 0, 0, 2, 2, 1, 0, 1, 0, 1, 1, 0, 0, 1, 2, 2, 0, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 0, 2, 2, 2, 2, 2, 1, 2, 1, 0, 0, 0, 0, 1, 2, 1, 0, 1, 0, 0, 0, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 2, 1, 1, 2, 1, 1, 0, 1, 1, 1, 2, 0, 1, 2, 2, 1, 2, 2, 0, 0, 2, 1, 1, 2, 0, 1, 2, 1, 0, 1, 0, 0, 0, 2, 1, 2, 0, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 0, 2, 0, 0, 2, 1, 2, 2, 2, 1, 2, 0, 1, 0, 2, 2, 1, 1, 1, 0, 0, 1, 2, 2, 2, 0, 1, 2, 1, 2, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 0, 0, 2, 0, 1, 1, 2, 1, 0, 0, 2, 0, 1, 2, 0, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 2, 2, 2, 0, 2, 0, 1, 0, 2, 2, 2, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 0, 2, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 1, 2, 0, 2, 1, 0, 2, 2, 0, 1, 2, 1, 0, 2, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 2, 2, 2, 2, 1, 2, 2, 0, 0, 2, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 2, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 2, 1, 2, 1, 0, 2, 2, 1, 1, 0, 1, 1, 1, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 1, 0, 2, 1, 0, 0, 0, 2, 1, 0, 1, 2, 2, 1, 1, 2, 1, 0, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 1, 1, 0, 0, 0, 2, 0, 0, 2, 1, 2, 2, 1, 1, 0, 0, 1, 2, 1, 2, 2, 1, 0, 0, 0, 1, 1, 0, 0, 2, 2, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 2, 1, 1, 2, 0, 1, 0, 0, 1, 1, 2, 1, 2, 0, 0, 1, 2, 1, 0, 2, 1, 0, 1, 0, 2, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 2, 0, 0, 1, 0, 1, 0, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2, 0, 2, 2, 0, 1, 1, 2, 0, 1, 0, 1, 0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 0, 2, 1, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 1, 2, 2, 2, 0, 1, 1, 2, 0, 1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 1, 2, 1, 1, 1, 1, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 2, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 2, 2, 0, 2, 0, 1, 2, 0, 1, 1, 2, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 0, 2, 0, 1, 1, 1, 2, 0, 1, 2, 2, 2, 2, 1, 0, 1, 1, 0, 1, 1, 0, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 2, 0, 2, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 2, 0, 0, 2, 1, 2, 2, 1, 2, 1, 0, 1, 0, 0, 1, 1, 2, 1, 2, 0, 1, 2, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 2, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 0, 0, 2, 1, 1, 0, 0, 2, 2, 2, 1, 0, 1, 0, 2, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 2, 0, 1, 0, 2, 1, 2, 1, 1, 0, 0, 0, 2, 0, 2, 0, 1, 2, 1, 2, 0, 1, 1, 2, 2, 0, 1, 0, 0, 0, 0, 2, 2, 0, 0, 1, 2, 2, 2, 2, 2, 0, 2, 0, 0, 2, 2, 0, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 0, 0, 2, 1, 0, 2, 0, 1, 2, 0, 0, 2, 0, 2, 1, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 2, 0, 2, 2, 2, 2, 0, 1, 0, 2, 1, 1, 1, 0, 2, 1, 0, 2, 0, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2, 1, 0, 1, 2, 1, 0, 2, 1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 2, 1, 2, 1, 1, 1, 1, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 2, 0, 0, 0, 0, 2, 0, 2, 0, 1, 2, 0, 2, 1, 2, 1, 0, 1, 2, 2, 2, 2, 1, 0, 1, 0, 1, 2, 2, 2, 1, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 2, 2, 0, 1, 0, 2, 1, 2, 0, 0, 0, 1, 1, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 1, 0, 1, 2, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 2, 1, 0, 1, 1, 2, 2, 0, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 1, 0, 1, 1, 0, 2, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 2, 1, 2, 2, 1, 2, 0, 0, 2, 2, 2, 2, 1, 2, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 1, 2, 1, 2, 0, 2, 2, 1, 0, 2, 0, 2, 2, 1, 0, 1, 2, 0, 0, 2, 2, 0, 0, 2, 1, 1, 2, 2, 0, 2, 2, 0, 2, 1, 0, 0, 2, 1, 1, 2, 1, 0, 2, 2, 1, 2, 1, 1, 2, 2, 0, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 1, 2, 2, 0, 1, 0, 1, 1, 0, 2, 1, 1, 1, 2, 0, 0, 1, 0, 2, 2, 2, 1, 0, 0, 0, 2, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 2, 2, 0, 1, 1, 1, 2, 1, 0, 0, 2, 1, 1, 2, 2, 0, 1, 0, 2, 1, 2, 1, 2, 2, 0, 1, 0, 2, 1, 2, 0, 2, 0, 1, 0, 1, 2, 2, 2, 2, 0, 1, 2, 0, 1, 1, 0, 1, 2, 2, 2, 1, 1, 0, 0, 2, 2, 0, 0, 1, 2, 1, 1, 0, 0, 2, 1, 1, 1, 1, 0, 2, 1, 1, 2, 0, 0, 2, 2, 1, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0, 1, 0, 0, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 0, 1, 1, 1, 2, 2, 1, 0, 2, 0, 2, 1, 0, 1, 0, 2, 1, 1, 2, 1, 2, 1, 2, 0, 0, 0, 2, 2, 2, 0, 2, 1, 1, 2, 0, 0, 1, 0, 1, 0, 2, 2, 1, 1, 1, 0, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 1, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 2, 1, 2, 2, 1, 0, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 1, 2, 2, 2, 0, 2, 0, 2, 1, 2, 1, 1, 2, 2, 2, 0, 1, 0, 0, 1, 0, 2, 1, 1, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 2, 2, 0, 0, 2, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 1, 0, 2, 2, 2, 1, 2, 1, 2, 1, 1, 2, 0, 2, 2, 1, 2, 0, 1, 1, 2, 1, 2, 0, 2, 2, 1, 2, 1, 2, 0, 2, 2, 1, 2, 2, 0, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 0, 1, 0, 1, 2, 2, 1, 1, 0, 2, 1, 2, 1, 2, 0, 0, 2, 2, 2, 0, 1, 1, 1, 1, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 0, 0, 2, 1, 0, 2, 2, 0, 1, 1, 1, 1, 1, 0, 2, 2, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 2, 2, 2, 1, 1, 0, 0, 2, 0, 2, 1, 2, 1, 2, 0, 2, 2, 1, 1, 0, 1, 0, 1, 1, 1, 1, 2, 0, 1, 1, 2, 2, 2, 0, 2, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 0, 2, 0, 2, 1, 1, 0, 2, 1, 2, 2, 0, 1, 0, 1, 2, 0, 1, 2, 0, 1, 0, 1, 2, 2, 2, 1, 0, 0, 1, 2, 2, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 0, 2, 2, 1, 1, 0, 2, 1, 1, 1, 1, 0, 0, 0, 1, 1, 2, 2, 1, 2, 0, 2, 0, 2, 0, 1, 2, 2, 1, 0, 0, 1, 1, 1, 1, 0, 2, 0, 0, 0, 1, 0, 2, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 0, 2, 1, 1, 0, 1, 2, 1, 0, 2, 1, 0, 0, 2, 2, 1, 0, 2, 0, 2, 0, 1, 2, 1, 0, 2, 1, 0, 1, 0, 1, 0, 2, 0, 0, 2, 1, 2, 0, 1, 2, 1, 0, 2, 1, 1, 1, 0, 1, 1, 0, 0, 1, 2, 2, 1, 2, 2, 2, 2, 2, 1, 1, 0, 2, 2, 0, 1, 2, 0, 0, 1, 1, 2, 2, 2, 0, 1, 1, 1, 1, 1, 2, 1, 2, 0, 2, 2, 0, 2, 1, 1, 1, 2, 1, 0, 0, 2, 0, 1, 0, 1, 0, 0, 1, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 2, 1, 2, 0, 1, 1, 2, 1, 2, 2, 0, 0, 2, 0, 1, 1, 2, 2, 2, 0, 2, 1, 2, 0, 2, 1, 1, 0, 0, 1, 2, 0, 2, 1, 0, 2, 2, 1, 0, 0, 1, 1, 0, 0, 2, 2, 1, 2, 2, 2, 1, 2, 1, 0, 2, 0, 1, 1, 2, 2, 2, 2, 0, 0, 1, 1, 0, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 2, 0, 2, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1, 0, 2, 1, 2, 2, 0, 2, 1, 0, 0, 1, 1, 2, 0, 1, 0, 2, 1, 1, 1, 0, 2, 0, 1, 0, 2, 2, 1, 1, 0, 1, 2, 2, 1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           id  predictions\n",
       "0  aa2510d454            0\n",
       "1  865d1c7b16            1\n",
       "2  6d9fa191e6            0\n",
       "3  f11f1ffffe            2\n",
       "4  40a9b0f08e            0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>predictions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>aa2510d454</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>865d1c7b16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>6d9fa191e6</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>f11f1ffffe</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>40a9b0f08e</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "sub = test_pd.id.copy().to_frame()\n",
    "sub[\"predictions\"] = li\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}